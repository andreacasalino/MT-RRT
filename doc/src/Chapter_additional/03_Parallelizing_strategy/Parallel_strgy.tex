\chapter{Parallel RRT}
\label{chap:parallel_RRT}

This Chapter will provide details about the strategies adopted for parallelizing RRT that MT$\_$RRT contains. Further details are contained also in \cite{MT_RRT}, which is the publication were for the first time MT$\_$RRT was presented. In \cite{MT_RRT} you can find also a comparison in terms of computational times.
\\
Each strategy described in the following Sections is able to parallelize the three RRT versions exposed in Sections \ref{sec:RRT_single}, \ref{sec:RRT_bidir} and \ref{sec:RRT_star}. The only exception must be made only for the strategy exposed in Section \ref{sec:strtg_multi}, for which a bidirectional RRT (Section \ref{sec:RRT_bidir}) cannot be applied.

 \begin{figure}
\begin{tabular}{cc}
\begin{minipage}[t]{0.49\textwidth}
 \def\svgwidth{0.69 \columnwidth}
 \import{../src/Chapter_additional/03_Parallelizing_strategy/image/}{query_parall.pdf_tex} 
 (a) Schematic representation of the parallelization of the query activities approach.
\end{minipage}
 &  
\begin{minipage}[t]{0.49\textwidth}
 \def\svgwidth{0.79 \columnwidth}
 \import{../src/Chapter_additional/03_Parallelizing_strategy/image/}{shared_parall.pdf_tex} 
 (b) Schematic representation of the parallel extensions of a common tree approach.
\end{minipage}
 \\
\begin{minipage}[t]{0.49\textwidth}
 \def\svgwidth{0.59 \columnwidth}
 \import{../src/Chapter_additional/03_Parallelizing_strategy/image/}{copied_parall.pdf_tex} 
 (c) Schematic representation of the parallel expansions of copied trees approach.
\end{minipage}
 & 
\begin{minipage}[t]{0.49\textwidth}
 \def\svgwidth{0.79 \columnwidth}
 \import{../src/Chapter_additional/03_Parallelizing_strategy/image/}{multi_agent.pdf_tex} 
 (d) Schematic representation of the multi agent approach. 
\end{minipage}
\end{tabular}
	 \caption{Approaches adopted for parallelize RRT.}
 \label{fig:parall_strategies}
\end{figure}

\subsection{Parallelization of the query activities}

All the RRT versions spend a significant time in performing query operations on the tree, i.e. operations that require to traverse all the tree.
Such operations are mainly the nearest neighbour search, algorithm \ref{alg:NearNeigh}, and the determination of the near set, algorithm \ref{alg:Expand_star}.
\\
The key idea is to perform the above query operations with a parallel for, where at an average all the threads process the same amount of nodes in the tree, computing their distances for determine the nearest neighbour or the near set. 
The parallel regions are not re-opened and closed every time, but a thread pooling strategy is adopted: all the threads are spawn when a new planning problem must be solved and remain active and ready to perform the parallel for described before.
All the operations of the RRT (regardless the version considered) are done by the main thread, which notifies at the proper time when a new query operation must be process collectively by all the threads. Figure \ref{fig:parall_strategies}.a summarizes the approach.
\\
The class implementing this approach is Planner$\_$query$\_$parall.

\subsection{Shared tree critical regions}

Another way to obtain a parallelization is to actually do simultaneously, every single step of the RRT versions. Therefore, we can imagine having threads sharing a common tree (or two trees in the case of a bidirectional strategy), executing in parallel every step of the expansion process. Some critical sections must be designed to allow the threads executing the maintenance of the shared tree(s) (inserting new nodes or executing new rewirds) one at a time.
More precisely, the steer is done outside and only the insertion of the steered configuration in the tree is performed inside a critical region.
Similarly, the extending procedure of the RRT*, algorithm \ref{alg:Expand_star}, is modified by shifting the determination of the near set and the Rewird procedure in a critical section. Figure \ref{fig:parall_strategies}.b summarizes the approach.
\\
The class implementing this approach is Planner$\_$shared$\_$parall.


\subsection{Parallel expansions of copied trees}
\label{sec:strtg_copied}

To limit as much as possible the overheads induced by the presence of critical sections, we can consider a version similar to the one proposed in the previous Section, but for which every thread has a private copy of the search tree. After a new node is added by a thread to its own tree, $P-1$ copies are computed and dispatched \footnote{They are dispatched into proper buffer, but not directly inserted in the private copies of the other trees.} to the other threads, were $P$ is the number of working threads.
Sporadically, all the threads take into account the list of nodes received from the others and insert them into their private trees. This mechanism is able to avoid the simultaneous modification of a tree by two different threads, avoiding the use of critical sections.
\\
When considering the bidirectional RRT, the mechanism is analogous but introducing for every thread a private
copy of both the involved trees. 
\\
Instead, the RRT* version is slightly modified. Indeed, the rewirds done by a thread on its own tree are not dispatched to the others.
At the same time, each thread consider all the nodes produced and added to its own tree when doing their own rewirds.
When searching the best solution at the end of all the iterations, the best connections among all the trees in every threads are taken into account. Indeed, the predecessor of a node is assumed to be the parent with the lowest cost to go among the ones associated to each clones. Figure \ref{fig:parall_strategies}.c summarizes the approach.
\\
Clearly, the amount memory required by this approach is significantly high, since multiple copies of a node must live in the different threads.
This can be a problem to account for.
\\
The class implementing this approach is Planner$\_$copied$\_$parall.
 
%METTERE figura che spiega calcolo path to root


\subsection{Multi agents approach}
\label{sec:strtg_multi}

The strategy described in this Section aims at exploiting a significant number of threads, with both a reduced synchronizing need and allocation memory requirements. To this purpose, a variant of the RRT was developed for which every exploring thread has not the entire knowledge of the
tree, but it is conscious of a small portion of it. 
Therefore, we can deploy many threads to simultaneously explore the state space $\mathcal{X}$ (ignoring the results found by the other agents) for
a certain amount of iterations. After completing this sub-exploration task, all data incoming from the agents are collected and stored in a centralized data base while the agents wait to begin a new explorative batch, completely forgetting the nodes found at the previous iteration. 
The described behaviour resembles one of many exploring ants, which reports the exploring data to a unique anthill.
\\
Notice that there is no need to physically copy the states computed by the agents when inserting them into the central database, since threads share a common memory: the handler of the node is simply moved. 
\\
When considering this approach a bidirectional search is not implementable, while the RRT* can be extended as reported in the following.
Essentially, the agents perform a standard non-optimal exploration, implementing the steps of a canonical RRT, Section \ref{sec:RRT_single}.
Then, at the time of inserting the nodes into the common database, the rewirds are done by the main thread.
\\
The described multi agent approach is clearly a modification of the canonical RRT versions, since the agents start exploring every time from some new roots, ignoring all the previously computed nodes. However, it was empirically found that the global behaviour of the path search is not deteriorated and the optimality properties of the RRT* seems to be preserved.
\\
Before concluding this Section it is worthy to notice that the mean time spent for the querying operations is considerably
lower, since such operations are performed by agents considering only their own local reduced size trees.
\\
Figure \ref{fig:parall_strategies}.d summarizes the approach.
The class implementing this approach is Planner$\_$multi$\_$agents.
